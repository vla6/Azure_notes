{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebaf8ad1",
   "metadata": {},
   "source": [
    "# HyperDriveStep() Hang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0c4018-8f9b-4ddb-a8d1-5818034e6ecc",
   "metadata": {},
   "source": [
    "This script is run in our environment and causes an indefinite hang in HyperDriveStep().  The hang occurs for any call to HyperDriveStep(), so here I have just a dummy function.  The code being run is unimportant.\n",
    "\n",
    "See also https://learn.microsoft.com/en-us/answers/questions/889157/why-is-my-hyperdrive-step-not-completing-even-when?comment=question#newest-question-comment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb430ef-0826-4a95-bc09-88b7f890d1bb",
   "metadata": {},
   "source": [
    "## Setup -- Modify these to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a731f1d2-e840-4495-bce7-91c13cd86d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of workspace, etc. for Workspace.get()\n",
    "WS_NAME = \"XX\"\n",
    "WS_ID = \"XX\"\n",
    "WS_RESOURCE_GRP = \"XX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eda7742-fa62-4cfb-860f-4d63c1ffbb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment, for Environment.get()\n",
    "ENV_NAME = \"XX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca62dd9-97e0-46ad-b839-b160e4f4a547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute target (cluster)\n",
    "COMP_TARGET = 'XX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe8b8b6-f258-4139-b4dd-e54aac954d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of datastore for metrics\n",
    "DATASTORE_NAME = 'XX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6c91b8-138f-4ea6-95bc-37d8c540551d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of concurrent parallel runs - aim to use about 80% of the cluster capacity, or just set to something small like 2-3\n",
    "NUM_PROC = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0941e7f-1880-4427-b792-113365a79a42",
   "metadata": {},
   "source": [
    "## Dummy Python Script\n",
    "Write to text in the current directory.  Will be used in ScriptRunConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f341b33-15bd-4a60-9e28-fa5c75ec7037",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile empty_step.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from azureml.core import Run\n",
    "from azureml.core import Datastore, Dataset\n",
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "run = Run.get_context()\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "parser = argparse.ArgumentParser()                  \n",
    "\n",
    "parser.add_argument('--learning_rate', type=float, default=0.1,\n",
    "                    help='Learning Rate')\n",
    "parser.add_argument('--min_child_weight', type=float, default=1,\n",
    "                    help='Controls Overfitting')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Just log something\n",
    "def main():\n",
    "    run.log('Runtype', 'TEST')\n",
    "    run.log('AUC', '0.7')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17e5835",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70058390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset, ScriptRunConfig, Experiment, Datastore, Environment\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.pipeline.core import PipelineData, Pipeline, PipelineRun, StepSequence, TrainingOutput\n",
    "from azureml.pipeline.steps import HyperDriveStep\n",
    "from azureml.train.hyperdrive import HyperDriveConfig, PrimaryMetricGoal, BayesianParameterSampling, uniform, HyperDriveRun\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae96199",
   "metadata": {},
   "source": [
    "## Workspace and compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f40e2a-bbcf-4634-8394-fc8e93bc013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.get(\n",
    "            name=WS_NAME, \n",
    "            subscription_id=WS_ID,\n",
    "            resource_group=WS_RESOURCE_GRP\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b85612-a6f1-4f6e-a7f4-b8ca870bca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_env = Environment.get(workspace=ws, name=ENV_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f9fe83-022c-4d38-b730-a1627805c412",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datastore = Datastore.get(ws, DATASTORE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c580eac",
   "metadata": {},
   "source": [
    "## Create the Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe7069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline data for parameter tuning\n",
    "step_metrics_data = PipelineData(name='hanging_step', datastore=train_datastore,\n",
    "                                pipeline_output_name='step_metrics',\n",
    "                                training_output=TrainingOutput(type='Metrics'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f032573-09cd-4329-b351-6168283b290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run config with un-tuned parameters\n",
    "step_run_config = ScriptRunConfig(source_directory = '.', \n",
    "                                    script = './empty_step.py', \n",
    "                                    environment=std_env,\n",
    "                                    compute_target=COMP_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9c94fb-6129-48a0-9aeb-2d7b3c4c007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter sampling\n",
    "step_tuning = BayesianParameterSampling({\n",
    "    '--learning_rate': uniform(0.005,0.2),\n",
    "    '--min_child_weight': uniform(50,500)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c00b8c-5912-4569-8f51-c51145dcb55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I do a small number of max_total_runs so the hang happens quickly.\n",
    "# Ignore the warning.\n",
    "step_hyperdrive_config = HyperDriveConfig(\n",
    "    run_config = step_run_config,\n",
    "    hyperparameter_sampling=step_tuning,\n",
    "    primary_metric_name=\"AUC\",\n",
    "    primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
    "    max_total_runs = 3,  # Small number here to make it hang fast\n",
    "    max_concurrent_runs= NUM_PROC\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd07a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = HyperDriveStep(name = 'model-tune',\n",
    "                        hyperdrive_config = step_hyperdrive_config,\n",
    "                        outputs=[step_metrics_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbd1692-0400-4ab0-99d1-0110f7e62040",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f129ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_sequence = StepSequence(steps=[step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99e49e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(workspace=ws, steps=step_sequence, \n",
    "                    default_source_directory = '.',\n",
    "                    description= \"HyperDriveStep hang\")\n",
    "pipeline_exp = Experiment(ws,  'eechxgb-hang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8792df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run = pipeline_exp.submit(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5533367-edc5-4fdd-aa85-2498119bdf39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ea4df7-9eee-49ac-b78a-b07ad5cb8060",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
